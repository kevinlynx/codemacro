<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: dhtcrawler | loop in codes]]></title>
  <link href="http://codemacro.com/tags/dhtcrawler/atom.xml" rel="self"/>
  <link href="http://codemacro.com/"/>
  <updated>2014-04-06T10:35:51+08:00</updated>
  <id>http://codemacro.com/</id>
  <author>
    <name><![CDATA[Kevin Lynx]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[dhtcrawler的进程模型经验]]></title>
    <link href="http://codemacro.com/2014/02/21/dhtcrawler-process/"/>
    <updated>2014-02-21T00:00:00+08:00</updated>
    <id>http://codemacro.com/2014/02/21/dhtcrawler-process</id>
    <content type="html"><![CDATA[<p>距离写<a href="http://codemacro.com/2013/07/02/dhtcrawler2/">dhtcrawler</a>已经有半年时间。半年前就想总结点心得经验，但最后写出来的并没有表达出我特别有感慨的地方。最近又被人问到这方面的经验问题，才静下心来思考整理了下。</p>

<p>我的经验是关于在写一个网络项目时所涉及到的架构（或者说是模型）。</p>

<p>在dhtcrawler中，一个主要的问题是：程序在网络中需要尽可能快尽可能多地收集请求，然后程序需要尽可能快地加工处理这些信息。本质上就这么简单，我觉得很多网络系统面临的都可能是类似的问题。</p>

<p>详细点说，dhtcrawler高峰期每天会收到2000万的DHT协议请求，收到这些请求后，dhtcrawler需要对这些请求做处理，包括：合并相同的请求；从外部网站请求下载种子文件；新增/更新种子信息到数据库；建立种子sphinx索引等。在实际运行期间，高峰期每天能新录入14万个种子。</p>

<p>那么如何架构这个系统来让处理速度尽可能地快呢？首先，毫无疑问这个系统是多线程/多进程，甚至是分布式的。写一个多线程程序学几个API谁都会，但是如何组织这些线程以让系统最优则是一个较困难的问题。根据dhtcrawler的经验，我简单总结了以下几种模型/架构：</p>

<!-- more -->


<h2>简单模型</h2>

<p>约定一个线程/进程为worker。那么简单模型就是每一个worker都包含了完整的处理逻辑，从收到请求，到把该请求处理完毕。</p>

<pre><code>Req -&gt; Worker -&gt; Process -&gt; O
</code></pre>

<p>当然，我们可以给系统配置若干个Worker，以求最大化效率。例子中，Req的来源是非常快非常多的，而 Process过程相对而言则非常慢，涉及到各种IO操作（从外部网站下载种子，写入数据库等）。</p>

<p>这个模型的整体效率完全受限于Process的过程。如果Req的来源速度还不是稳定的，那么Process的速度将严重影响系统的吞吐性。</p>

<p>当然这个模型的优点就是特别简单，咋并发系统中简单有利于维护和调试。</p>

<h2>粗粒度分离模型</h2>

<p>分离模型指的是把Req的获取过程和处理过程分离开来。也就是合理地将系统中慢的部分和快的部分分离。然后两者之间通过一些数据共享方式来交互。</p>

<pre><code>Req -&gt; ReqWorker -&gt; Pool
Pool -&gt; ReqProcessor -&gt; O
</code></pre>

<p>这个时候，ReqWorker可以以尽可能快的速度收集Req，不用受限于ReqProcessor的处理速度。</p>

<p>这个Pool的实现有很多方式。这种模型有点类似于线程/进程间的交互，典型的生产者消费者问题。在需要同步的实现中，Pool可能需要写的比较精巧。</p>

<p>Pool可以放置在内存中。也就是ReqWorker把收到的请求稍作加工就放到内存中。这里的稍作加工可以是一段时间里的重复数据合并。ReqProcessor则可以以一定策略从这个内存中取得Req。这个策略可以是以一定时间间隔，或者基于ReqWorker的通知。</p>

<p>在erlang中，可以以一个单独的进程来维护这个Pool。那么这里就是通过erlang的进程来实现数据的同步。本质上也是基于erlang进程的mailbox机制。这个维护Pool的进程逻辑足够简单，可以快速响应ReqWorker的Req压入，以及ReqProcessor的Req取出。</p>

<p><strong>在用erlang的过程中，很多时候就是在平衡这种(actor)[http://en.wikipedia.org/wiki/Actor_model]进程模式中各种进程间的协调程度。</strong>平衡不好会导致两种情况：a)进程mailbox暴涨最后内存耗尽；b)消费者进程请求资源超时。</p>

<p>Pool被放置在内存中时，本身也可能有问题。例如数据量过大，无论是直接基于OS的程序还是基于erlang/jvm等虚拟机的程序，都可能在这个时候出现问题。并且，把数据放置在内存中也可能由于程序不稳定导致数据丢失。</p>

<p>dhtcrawler中把很多中间数据放置在数据库中。当然这里是个权衡问题。更复杂的系统里我相信就可以加入内存数据库之类的系统。</p>

<p>使用了分离模型之后，还是可以配置每种进程的数量，但是这里的问题在于很难平衡每种进程所配置的比例，以最大化使用CPU内存之类的资源。</p>

<h2>细粒度分离模型</h2>

<p>异步程序编写起来始终比同步程序更困难。在异步系统中需要加入各种例如事件、消息等机制。一个简单的逻辑可能会分散到程序的不同地方。对于资源的管理，错误的排除，性能的调优都带来了困难。</p>

<p>细粒度分离模型同粗粒度模型一样，只不过对进程种类的划分粒度更细。在erlang这种使用进程来组织程序合情合理的语言中，就可以做到每一种进程仅仅只做一种事情，就像函数设计原则一样，功能单一。</p>

<p>以dhtcrawler为例，整个系统可以划分为如下若干种进程：</p>

<ul>
<li>请求收集，用于收集请求，涉及到网络操作和数据库操作</li>
<li>请求分类，将请求按是否需要从外部网站下载种子分类，仅涉及到数据库操作</li>
<li>种子下载，从外部网站下载种子</li>
<li>种子索引，建立sphinx索引</li>
</ul>


<p>部分简单的进程其代码实现量不到千行。在erlang的进程中也是简单的几个消息，维护起来非常容易。</p>

<p>从上面的这种模型中，进程之间全部通过数据库做交互，那就很自然地可以发展为分布式系统。数据库再通过集群之类的技术，可以较高地提升系统的吞吐量。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dhtcrawler2换用sphinx搜索]]></title>
    <link href="http://codemacro.com/2013/08/08/sphinx-dhtcrawler/"/>
    <updated>2013-08-08T00:00:00+08:00</updated>
    <id>http://codemacro.com/2013/08/08/sphinx-dhtcrawler</id>
    <content type="html"><![CDATA[<p>dhtcrawler2最开始使用mongodb自带的全文搜索引擎搜索资源。搜索一些短关键字时很容易导致erlang进程call timeout，也就是查询时间太长。对于像<code>avi</code>这种关键字，搜索时间长达十几秒。搜索的资源数量200万左右。这其中大部分资源只是对root文件名进行了索引，即对于多文件资源而言没有索引单个文件名。索引方式有部分资源是按照字符串子串的形式，没有拆词，非常占用存储空间；有部分是使用了rmmseg（我编译了rmmseg-cpp作为erlang nif库调用 <a href="https://github.com/kevinlynx/erl-rmmseg">erl-rmmseg</a>）进行了拆词，占用空间小了很多，但由于词库问题很多片里的词汇没拆出来。</p>

<p>很早以前我以为搜索耗时的原因是因为数据库太忙，想部署个mongodb集群出来。后来发现数据库没有任何读写的状态下，查询依然慢。终于只好放弃mongodb自带的文本搜索。于是我改用sphinx。简单起见，我直接下载了<a href="http://www.coreseek.cn/">coreseek4.1</a>（sphinx的一个支持中文拆词的包装）。</p>

<p>现在，已经导入了200多万的资源进sphinx，并且索引了所有文件名，索引文件达800M。对于<code>avi</code>关键字的搜索大概消耗0.2秒的时间。<a href="http://bt.cm/e/http_handler:search?q=avi">搜索试试</a>。</p>

<p>以下记录下sphinx在dhtcrawler的应用</p>

<h3>sphinx简介</h3>

<p>sphinx包含两个主要的程序：indexer和searchd。indexer用于建立文本内容的索引，然后searchd基于这些索引提供文本搜索功能，而要使用该功能，可以遵循searchd的网络协议连接searchd这个服务来使用。</p>

<p>indexer可以通过多种方式来获取这些文本内容，文本内容的来源称为数据源。sphinx内置mysql这种数据源，意思是可以直接从mysql数据库中取得数据。sphinx还支持xmlpipe2这种数据源，其数据以xml格式提供给indexer。要导入mongodb数据库里的内容，可以选择使用xmlpipe2这种方式。</p>

<!-- more -->


<h3>sphinx document</h3>

<p>xmlpipe2数据源需要按照以下格式提交：</p>

<pre><code>&lt;sphinx:docset&gt;
    &lt;sphinx:schema&gt;
        &lt;sphinx:field name="subject"/&gt;
        &lt;sphinx:field name="files"/&gt;
        &lt;sphinx:attr name="hash1" type="int" bits="32"/&gt;
        &lt;sphinx:attr name="hash2" type="int" bits="32"/&gt;
    &lt;/sphinx:schema&gt;
    &lt;sphinx:document id="1"&gt;
        &lt;subject&gt;this is the subject&lt;/subject&gt;
        &lt;files&gt;file content&lt;/files&gt;
        &lt;hash1&gt;111&lt;/hash1&gt;
    &lt;/sphinx:document&gt;
&lt;/sphinx:docset&gt;
</code></pre>

<p>该文件包含两大部分：<code>schema</code>和<code>documents</code>，其中<code>schema</code>又包含两部分：<code>field</code>和<code>attr</code>，其中由<code>field</code>标识的字段就会被indexer读取并全部作为输入文本建立索引，而<code>attr</code>则标识查询结果需要附带的信息；<code>documents</code>则是由一个个<code>sphinx:document</code>组成，即indexer真正要处理的数据。注意其中被<code>schema</code>引用的属性名。</p>

<p>document一个很重要的属性就是它的id。这个id对应于sphinx需要唯一，查询结果也会包含此id。一般情况下，此id可以直接是数据库主键，可用于查询到详细信息。searchd搜索关键字，其实可以看作为搜索这些document，搜索出来的结果也是这些document，搜索结果中主要包含schema中指定的attr。</p>

<h3>增量索引</h3>

<p>数据源的数据一般是变化的，新增的数据要加入到sphinx索引文件中，才能使得searchd搜索到新录入的数据。要不断地加入新数据，可以使用增量索引机制。增量索引机制中，需要一个主索引和一个次索引(delta index)。每次新增的数据都建立为次索引，然后一段时间后再合并进主索引。这个过程主要还是使用indexer和searchd程序。实际上，searchd是一个需要一直运行的服务，而indexer则是一个建立完索引就退出的工具程序。所以，这里的增量索引机制，其中涉及到的“每隔一定时间就合并”这种工作，需要自己写程序来协调（或通过其他工具）</p>

<h3>sphinx与mongodb</h3>

<p>上面提到，一般sphinx document的id都是使用的数据库主键，以方便查询。但mongodb中默认情况不使用数字作为主键。dhtcrawler的资源数据库使用的是资源info-hash作为主键，这无法作为sphinx document的id。一种解决办法是，将该hash按位拆分，拆分成若干个sphinx document attr支持位数的整数。例如，info-hash是一个160位的id，如果使用32位的attr（高版本的sphinx支持64位的整数），那么可以把该info-hash按位拆分成5个attr。而sphinx document id则可以使用任意数字，只要保证不冲突就行。当获得查询结果时，取得对应的attr，组合为info-hash即可。</p>

<p>mongodb默认的Object id也可以按这种方式拆分。</p>

<h3>dhtcrawler2与sphinx</h3>

<p>dhtcrawler2中我自己写了一个导入程序。该程序从mongodb中读出数据，数据到一定量时，就输出为xmlpipe2格式的xml文件，然后建立为次索引，最后合并进主索引。过程很简单，包含两次启动外部进程的工作，这个可以通过erlang中os:cmd完成。</p>

<p>值得注意的是，在从mongodb中读数据时，使用skip基本是不靠谱的，skip 100万个数据需要好几分钟，为了不增加额外的索引字段，我只好在<code>created_at</code>字段上加索引，然后按时间段来读取资源，这一切都是为了支持程序关闭重启后，可以继续上次工作，而不是重头再来。200万的数据，已经处理了好几天了。</p>

<p>后头数据建立好了，需要在前台展示出来。erlang中似乎只有一个sphinx客户端库：<a href="https://github.com/kevsmith/giza">giza</a>。这个库有点老，写成的时候貌似还在使用sphinx0.9版本。其中查询代码包含了版本判定，已经无法在我使用的sphinx2.x版本中使用。无奈之下我只好修改了这个库的源码，幸运的是查询功能居然是正常的，意味着sphinx若干个版本了也没改动通信协议？后来，我为了取得查询的统计信息，例如消耗时间以及总结果，我再一次修改了giza的源码。新的版本可以在我的github上找到：<a href="https://github.com/kevinlynx/giza">my giza</a>，看起来我没侵犯版本协议吧？</p>

<p>目前dhtcrawler的搜索，先是基于sphinx搜索出hash列表，然后再去mongodb中搜索hash对应的资源。事实上，可以为sphinx的document直接附加这些资源的描述信息，就可以避免去数据库查询。但我想，这样会增加sphinx索引文件的大小，担心会影响搜索速度。实际测试时，发现数据库查询有时候还真的很消耗时间，尽管我做了分页，以使得单页仅对数据库进行少量查询。</p>

<h3>xml unicode</h3>

<p>在导入xml到sphinx的索引过程中，本身我输出的内容都是unicode的，但有很多资源会导致indexer解析xml出错。出错后indexer直接停止对当前xml的处理。后来查阅资料发现是因为这些无法被indexer处理的xml内容包含unicode里的控制字符，例如 ä (U+00E4)。我的解决办法是直接过滤掉这些控制字符。unicode的控制字符参看<a href="http://www.utf8-chartable.de/">UTF-8 encoding table and Unicode characters</a>。在erlang中干这个事居然不复杂：</p>

<p><div class="highlight"><pre><code class="erlang"><span class="nf">strip_invalid_unicode</span><span class="p">(</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&gt;&gt;</span><span class="p">)</span> <span class="o">-&gt;&lt;/</span><span class="n">p</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="err">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="err">&amp;</span><span class="n">gt</span><span class="p">;;</span>
<span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">strip_invalid_unicode</span><span class="p">(</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="nv">C</span><span class="o">/</span><span class="n">utf8</span><span class="p">,</span> <span class="nv">R</span><span class="o">/</span><span class="n">binary</span><span class="o">&gt;&gt;</span><span class="p">)</span> <span class="o">-&gt;&lt;/</span><span class="n">p</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">case</span> <span class="n">is_valid_unicode</span><span class="p">(</span><span class="nv">C</span><span class="p">)</span> <span class="k">of</span>
    <span class="n">true</span> <span class="o">-</span><span class="err">&amp;</span><span class="n">gt</span><span class="p">;</span>
        <span class="nv">RR</span> <span class="o">=</span> <span class="n">strip_invalid_unicode</span><span class="p">(</span><span class="nv">R</span><span class="p">),</span>
        <span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="nv">C</span><span class="o">/</span><span class="n">utf8</span><span class="p">,</span> <span class="nv">RR</span><span class="o">/</span><span class="n">binary</span><span class="err">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="err">&amp;</span><span class="n">gt</span><span class="p">;;</span>
    <span class="n">false</span> <span class="o">-</span><span class="err">&amp;</span><span class="n">gt</span><span class="p">;</span>
        <span class="n">strip_invalid_unicode</span><span class="p">(</span><span class="nv">R</span><span class="p">)</span>
<span class="k">end</span><span class="p">;</span>
<span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">strip_invalid_unicode</span><span class="p">(</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;_,</span> <span class="nv">R</span><span class="o">/</span><span class="n">binary</span><span class="o">&gt;&gt;</span><span class="p">)</span> <span class="o">-&gt;&lt;/</span><span class="n">p</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">strip_invalid_unicode</span><span class="p">(</span><span class="nv">R</span><span class="p">).</span>
<span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">is_valid_unicode</span><span class="p">(</span><span class="nv">C</span><span class="p">)</span> <span class="k">when</span> <span class="nv">C</span> <span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="mi">16#20</span> <span class="o">-&gt;&lt;/</span><span class="n">p</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">false</span><span class="p">;</span>
<span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">is_valid_unicode</span><span class="p">(</span><span class="nv">C</span><span class="p">)</span> <span class="k">when</span> <span class="nv">C</span> <span class="o">&gt;=</span> <span class="mi">16#7f</span><span class="p">,</span> <span class="nv">C</span> <span class="o">=</span><span class="err">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="mi">16#ff</span> <span class="o">-&gt;&lt;/</span><span class="n">p</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">false</span><span class="p">;</span>
<span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">is_valid_unicode</span><span class="p">(_)</span> <span class="o">-&gt;&lt;/</span><span class="n">p</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">true</span><span class="p">.</span>
<span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</code></pre>
</div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[磁力搜索第二版-dhtcrawler2]]></title>
    <link href="http://codemacro.com/2013/07/02/dhtcrawler2/"/>
    <updated>2013-07-02T00:00:00+08:00</updated>
    <id>http://codemacro.com/2013/07/02/dhtcrawler2</id>
    <content type="html"><![CDATA[<p>接<a href="http://codemacro.com/2013/06/21/magnet-search-impl/">上篇</a>。</p>

<h2>下载使用</h2>

<p>目前为止dhtcrawler2相对dhtcrawler而言，数据库部分调整很大，DHT部分基本沿用之前。但单纯作为一个爬资源的程序而言，DHT部分可以进行大幅削减，这个以后再说。这个版本更快、更稳定。为了方便，我将编译好的erlang二进制文件作为git的主分支，我还添加了一些Windows下的批处理脚本，总之基本上下载源码以后即可运行。</p>

<p>项目地址：<a href="https://github.com/kevinlynx/dhtcrawler2">https://github.com/kevinlynx/dhtcrawler2</a></p>

<h3>使用方法</h3>

<ul>
<li>下载erlang，我测试的是R16B版本，确保erl等程序被加入<code>Path</code>环境变量</li>
<li><p>下载mongodb，解压即用：</p>

<pre><code>  mongod --dbpath xxx --setParameter textSearchEnabled=true
</code></pre></li>
<li><p>下载dhtcrawler2</p>

<pre><code>  git clone https://github.com/kevinlynx/dhtcrawler2.git
</code></pre></li>
<li><p>运行<code>win_start_crawler.bat</code></p></li>
<li>运行<code>win_start_hash.bat</code></li>
<li>运行<code>win_start_http.bat</code></li>
<li>打开<code>localhost:8000</code>查看<code>stats</code></li>
</ul>


<p>爬虫每次运行都会保存DHT节点状态，早期运行的时候收集速度会不够。dhtcrawler2将程序分为3部分：</p>

<ul>
<li>crawler，即DHT爬虫部分，仅负责收集hash</li>
<li>hash，准确来讲叫<code>hash reader</code>，处理爬虫收集的hash，处理过程主要涉及到下载种子文件</li>
<li>http，使用hash处理出来的数据库，以作为Web端接口</li>
</ul>


<p>我没有服务器，但程序有被部署在别人的服务器上：<a href="http://bt.cm">bt.cm</a>，<a href="http://222.175.114.126:8000/">http://222.175.114.126:8000/</a>。</p>

<!-- more -->


<h3>其他工具</h3>

<p>为了提高资源索引速度，我陆续写了一些工具，包括：</p>

<ul>
<li>import_tors，用于导入本地种子文件到数据库</li>
<li>tor_cache，用于下载种子到本地，仅仅提供下载的功能，hash_reader在需要种子文件时，可以先从本地取</li>
<li>cache_indexer，目前hash_reader取种子都是从torrage.com之类的种子缓存站点取，这些站点提供了种子列表，cache_indexer将这些列表导入数据库，hash_reader在请求种子文件前可以通过该数据库检查torrage.com上有无此种子，从而减少多余的http请求</li>
</ul>


<p>这些工具的代码都被放在dhtcrawler2中，可以查看对应的启动脚本来查看具体如何启动。</p>

<h3>OS/Database</h3>

<p>根据实际的测试效果来看，当收集的资源量过百万时（目前bt.cm录入近160万资源），4G内存的Windows平台，mongodb很容易就会挂掉。挂掉的原因全是1455，页面文件太小。有人建议不要在Windows下使用mongodb，Linux下我自己没做过测试。</p>

<p>mongodb可以部署为集群形式(replica-set)，当初我想把http部分的查询放在一个只读的mongodb实例上，但因为建立集群时，要同步已有的10G数据库，而每次同步都以mongodb挂掉结束，遂放弃。在目前bt.cm的配置中，数据库torrent的锁比例（db lock）很容易上50%，这也让http在搜索时，经常出现搜索超时的情况。</p>

<h2>技术信息</h2>

<p>dhtcrawler最早的版本有很多问题，修复过的最大的一个问题是关于erlang定时器的，在DHT实现中，需要对每个节点每个peer做超时处理，在erlang中的做法直接是针对每个节点注册了一个定时器。这不是问题，问题在于定时器资源就像没有GC的内存资源一样，是会由于程序员的代码问题而出现资源泄漏。所以，dhtcrawler第一个版本在节点数配置在100以上的情况下，用不了多久就会内存耗尽，最终导致erlang虚拟机core dump。</p>

<p>除了这个问题以外，dhtcrawler的资源收录速度也不是很快。这当然跟数据库和获取种子的速度有直接关系。尤其是获取种子，使用的是一些提供info-hash到种子映射的网站，通过HTTP请求来下载种子文件。我以为通过BT协议直接下载种子会快些，并且实时性也要高很多，因为这个种子可能未被这些缓存网站收录，但却可以直接向对方请求得到。为此，我还特地翻阅了相关<a href="http://www.bittorrent.org/beps/bep_0009.html">协议</a>，并且用erlang实现了（以后的文章我会讲到具体实现这个协议）。</p>

<p>后来我怀疑get_peers的数量会不会比announce_peer多，但是理论上一般的客户端在get_peers之后都是announce_peer，但是如果get_peers查询的peers恰好不在线呢？这意味着很多资源虽然已经存在，只不过你恰好暂时请求不到。实际测试时，发现get_peers基本是announce_peer数量的10倍。</p>

<p>将hash的获取方式做了调整后，dhtcrawler在几分钟以内以几乎每秒上百个新增种子的速度工作。然后，程序挂掉。</p>

<p>从dhtcrawler到今天为止的dhtcrawler2，中间间隔了刚好1个月。我的所有业余时间全部扑在这个项目上，面临的问题一直都是程序的内存泄漏、资源收录的速度不够快，到后来又变为数据库压力过大。每一天我都以为我将会完成一个稳定版本，然后终于可以去干点别的事情，但总是干不完，目前完没完都还在观察。我始终明白在做优化前需要进行详尽的数据收集和分析，从而真正地优化到正确的点上，但也总是凭直觉和少量数据分析就开始尝试。</p>

<p>这里谈谈遇到的一些问题。</p>

<h3>erlang call timeout</h3>

<p>最开始遇到erlang中<code>gen_server:call</code>出现<code>timeout</code>错误时，我还一直以为是进程死锁了。相关代码读来读去，实在觉得不可能发生死锁。后来发现，当erlang虚拟机压力上去后，例如内存太大，但没大到耗尽系统所有内存（耗进所有内存基本就core dump了），进程间的调用就会出现timeout。</p>

<p>当然，内存占用过大可能只是表象。其进程过多，进程消息队列太长，也许才是导致出现timeout的根本原因。消息队列过长，也可能是由于发生了<em>消息泄漏</em>的缘故。消息泄漏我指的是这样一种情况，进程自己给自己发消息（当然是cast或info），这个消息被处理时又会发送相同的消息，正常情况下，gen_server处理了一个该消息，就会从消息队列里移除它，然后再发送相同的消息，这不会出问题。但是当程序逻辑出问题，每次处理该消息时，都会发生多余一个的同类消息，那消息队列自然就会一直增长。</p>

<p>保持进程逻辑简单，以避免这种逻辑错误。</p>

<h3>erlang gb_trees</h3>

<p>我在不少的地方使用了gb_trees，dht_crawler里就可能出现<code>gb_trees:get(xxx, nil)</code>这种错误。乍一看，我以为我真的传入了一个<code>nil</code>值进去。然后我苦看代码，以为在某个地方我会把这个gb_trees对象改成了nil。但事情不是这样的，gb_tress使用一个tuple作为tree的节点，当某个节点没有子节点时，就会以nil表示。</p>

<p><code>gb_trees:get(xxx, nil)</code>类似的错误，实际指的是<code>xxx</code>没有在这个gb_trees中找到。</p>

<h3>erlang httpc</h3>

<p>dht_crawler通过http协议从torrage.com之类的缓存网站下载种子。最开始我为了尽量少依赖第三方库，使用的是erlang自带的httpc。后来发现程序有内存泄漏，google发现erlang自带的httpc早为人诟病，当然也有大神说在某个版本之后这个httpc已经很不错。为了省事，我直接换了ibrowse，替换之后正常很多。但是由于没有具体分析测试过，加之时间有点远了，我也记不太清细节。因为早期的http请求部分，没有做数量限制，也可能是由于我的使用导致的问题。</p>

<p>某个版本后，我才将http部分严格地与hash处理部分区分开来。相较数据库操作而言，http请求部分慢了若干数量级。在hash_reader中将这两块分开，严格限制了提交给httpc的请求数，以获得稳定性。</p>

<p>对于一个复杂的网络系统而言，分清哪些是耗时的哪些是不大耗时的，才可能获得性能的提升。对于hash_reader而言，处理一个hash的速度，虽然很大程度取决于数据库，但相较http请求，已经快很多。它在处理这些hash时，会将数据库已收录的资源和待下载的资源分离开，以尽快的速度处理已存在的，而将待下载的处理速度交给httpc的响应速度。</p>

<h3>erlang httpc ssl</h3>

<p>ibrowse处理https请求时，默认和erlang自带的httpc使用相同的SSL实现。这经常导致出现<code>tls_connection</code>进程挂掉的错误，具体原因不明。</p>

<h3>erlang调试</h3>

<p>首先合理的日志是任何系统调试的必备。</p>

<p>我面临的大部分问题都是内存泄漏相关，所以依赖的erlang工具也是和内存相关的：</p>

<ul>
<li><p>使用<code>etop</code>，可以检查内存占用多的进程、消息队列大的进程、CPU消耗多的进程等等：</p>

<pre><code>  spawn(fun() -&gt; etop:start([{output, text}, {interval, 10}, {lines, 20}, {sort, msg_q }]) end).
</code></pre></li>
<li><p>使用<code>erlang:system_info(allocated_areas).</code>检查内存使用情况，其中会输出系统<code>timer</code>数量</p></li>
<li>使用<code>erlang:process_info</code>查看某个具体的进程，这个甚至会输出消息队列里的消息</li>
</ul>


<h3>hash_writer/crawler</h3>

<p>crawler本身仅收集hash，然后写入数据库，所以可以称crawler为hash_writer。这些hash里存在大量的重复。hash_reader从数据库里取出这些hash然后做处理。处理过程会首先判定该hash对应的资源是否被收录，没有收录就先通过http获取种子。</p>

<p>在某个版本之后，crawler会简单地预先处理这些hash。它缓存一定数量的hash，接收到新hash时，就合并到hash缓存里，以保证缓存里没有重复的hash。这个重复率经过实际数据分析，大概是50%左右，即收到的100个请求里，有50个是重复的。这样的优化，不仅会降低hash数据库的压力，hash_reader处理的hash数量少了，也会对torrent数据库有很大提升。</p>

<p>当然进一步的方案可以将crawler和hash_reader之间交互的这些hash直接放在内存中处理，省去中间数据库。但是由于mongodb大量使用虚拟内存的缘故（内存映射文件），经常导致服务器内存不够（4G），内存也就成了珍稀资源。当然这个方案还有个弊端是难以权衡hash缓存的管理。crawler收到hash是一个不稳定的过程，在某些时间点这些hash可能爆多，而hash_reader处理hash的速度也会不太稳定，受限于收到的hash类别（是新增资源还是已存在资源）、种子请求速度、是否有效等。</p>

<p>当然，也可以限制缓存大小，以及对hash_reader/crawler处理速度建立关系来解决这些问题。但另一方面，这里的优化是否对目前的系统有提升，是否是目前系统面临的最大问题，却是需要考究的事情。</p>

<h3>cache indexer</h3>

<p>dht_crawler是从torrage.com等网站获取种子文件，这些网站看起来都是使用了相同的接口，其都有一个sync目录，里面存放了每天每个月索引的种子hash，例如 http://torrage.com/sync/。这个网站上是否有某个hash对应的种子，就可以从这些索引中检查。</p>

<p>hash_reader在处理新资源时，请求种子的过程中发现大部分在这些服务器上都没有找到，也就是发起的很多http请求都是404回应，这不但降低了系统的处理能力、带宽，也降低了索引速度。所以我写了一个工具，先手工将sync目录下的所有文件下载到本地，然后通过这个工具 (cache indexer) 将这些索引文件里的hash全部导入数据库。在以后的运行过程中，该工具仅下载当天的索引文件，以更新数据库。 hash_reader 根据配置，会首先检查某个hash是否存在该数据库中，存在的hash才可能在torrage.com上下载得到。</p>

<h3>种子缓存</h3>

<p>hash_reader可以通过配置，将下载得到的种子保存在本地文件系统或数据库中。这可以建立自己的种子缓存，但保存在数据库中会对数据库造成压力，尤其在当前测试服务器硬件环境下；而保存为本地文件，又特别占用硬盘空间。</p>

<h3>基于BT协议的种子下载</h3>

<p>通过http从种子缓存里取种子文件，可能会没有直接从P2P网络里取更实时。目前还没来得及查看这些种子缓存网站的实现原理。但是通过BT协议获取种子会有点麻烦，因为dht_crawler是根据<code>get_peer</code>请求索引资源的，所以如果要通过BT协议取种子，那么这里还得去DHT网络里查询该种子，这个查询过程可能会较长，相比之下会没有http下载快。而如果通过<code>announce_peer</code>来索引新资源的话，其索引速度会大大降低，因为<code>announce_peer</code>请求比<code>get_peer</code>请求少很多，几乎10倍。</p>

<p>所以，这里的方案可能会结合两者，新开一个服务，建立自己的种子缓存。</p>

<h3>中文分词</h3>

<p>mongodb的全文索引是不支持中文的。我在之前提到，为了支持搜索中文，我将字符串拆成了若干子串。这样的后果就是字符串索引会稍稍偏大，而且目前这一块的代码还特别简单，会将很多非文字字符也算在内。后来我加了个中文分词库，使用的是rmmseg-cpp。我将其C++部分抽离出来编译成erlang nif，这可以在我的github上找到。</p>

<p>但是这个库拆分中文句子依赖于词库，而这个词库不太新，dhtcrawler爬到的大部分资源类型你们也懂，那些词汇拆出来的比率不太高，这会导致搜索出来的结果没你想的那么直白。当然更新词库应该是可以解决这个问题的，目前还没有时间顾这一块。</p>

<h2>总结</h2>

<p>一个老外对我说过，"i have 2 children to feed, so i will not do this only for fun"。</p>

<p>你的大部分编程知识来源于网络，所以稍稍回馈一下不会让你丢了饭碗。</p>

<p>我很穷，如果你能让我收获金钱和编程成就，还不会嫌我穿得太邋遢，that's really kind of you。</p>
]]></content>
  </entry>
  
</feed>
